{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq3seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH73k4fmED-X",
        "colab_type": "text"
      },
      "source": [
        "##1.Introduction\n",
        "딥러닝을 약물 발견에 적용시키기 위해 사용되는 이용 가능한 labeled training data는 요구되는 data 양에 비해서 절대적으로 부족하다. Labeled data를 얻기 위하여 드는 비용이 매우 높기 떄문에 labeled data양을 늘리는 것은 매우 힘들다. 이 문제를 해결하기 위하여 semi-supervised deep learing modeling(반지도학습) 전략을 선택하였다. 이를 이용하면 딥러닝 프레임워크는 labeled data 와 unlabeled data 모두에서 학습을 할 수 있고 unlabeled data의 수는 거의 무한대로 사용할 수 있기 때문에 지도학습에 비해 많은 이점이 있다. 이러한 지도방식을 기반으로 한 방법을 seq3seq로 명명하였다. seq2seq는 1개의 입력과 1개의 출력으로 2개의 end를 포함하는데 반에 seq3seq 는 1개의 입력과 2개의 출력으로 3개의 end를 가진다. \n",
        "\n",
        "###Seq3seq 장점\n",
        "\n",
        "Labeled data와 unlabeled data를 모두 고려하여 우수한 추론 성능을 제공할 수 있다. 전문가의 주관적 지식에 대한 의존을 없애주는 데이터 드라이브이다. 사용할 수 있는 Unlabeled data의 수는 무수히 많기 때문에 수가 적은 labeled 데이터를 보완하여 추론 성능을 높일 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEPsnziTGhjZ",
        "colab_type": "text"
      },
      "source": [
        "##2. Methodology\n",
        "![대체 텍스트](https://d3i71xaburhd42.cloudfront.net/0b940de618127f3d149fa3ca8e8bbba4b1cc425d/4-Figure2-1.png)\n",
        "\n",
        "Labed data는 다른 분자 활동과 산도 등의 데이터를 포함하고 unlabed data는 SMILE문자열만 포함하고 있다.  \n",
        "\n",
        "End-to-end 반지도학습의 손실은 비지도학습의 손실과 지도학습의 손실 모두와 관련 되어있다. λ는 두 학습 사이의 균형을 맞추기 위해 제안된 변수이다. Unlabeled data의 경우 지도학습의 손실은 0이 될것이다. 이 경우 자가 회생 방법으로 훈련되어질 것이다. Labeled data의 경우 자가 회생 방법과 추론 모두가 훈련되어 진다. 결과적으로, end-to-end 모델은 최적의 추론 성능와 함께, 다단계 모델에서 제안된 모델에서보다 더 짧은 훈련 시간을 제공할 것으로 예상된다. \n",
        "\n",
        "Seq2seq에서 자연언어처리 영역에서 SMILES로 표현된 입력과 출력 사이에 번역에서 전사되는 과정에서 오류가 있었다. 그러나 Seq3seq에서는 이러한 오류가 나지 않고 잘 작용 하는 것을 보여주었다. \n",
        "\n",
        "![대체 텍스트](https://d3i71xaburhd42.cloudfront.net/0b940de618127f3d149fa3ca8e8bbba4b1cc425d/5-Figure3-1.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qQdymM8MZ7Z",
        "colab_type": "text"
      },
      "source": [
        "##3.EXPERIMENTS\n",
        "\n",
        "\n",
        "###Data set 출처<br>\n",
        "* Unlabeled Datset <br>\n",
        "> ZINC drug-like dataset : ZINC의 약물류 데이터 세트는 18,691,354개의 분자 SMILE 표현을 포함하고 있다.\n",
        "\n",
        "* Labeled Dataset\n",
        " 1. LogP <br>\n",
        ">LogP에서 총 10,850개의 샘플이 사용되었으며, 각 샘플에는 SMILE 문자열 한 쌍과 Water-Octanol 파티션 계수(LogP) 값이 포함되어 있다. 데이터에 라벨을 붙이기 위해 1.88의 임계값을 사용한다. LogP 값이 1.88보다 작은 표본은 음의 표본으로 분류되었고, 나머지는 양의 표본으로 분류되었다.\n",
        " 2. PM2-10k<br>\n",
        ">PM2-10k 데이터 세트에는 SMILEstrings 샘플 10,000개와 이진 비규칙 클래스 라벨이 포함되어 있다. 마찬가지로, 각 SMILE을 분류하기 위해 0.024896의 임계값을 사용했다. 임계값보다 큰 표본은 선호도 1로 간주되었다. 그렇지 않으면 0으로 표시된다.\n",
        "\n",
        "Seq3seq성능\n",
        "Seq3seq fingerprint는 네트워크 구조 선택에 있어서 유용하게 사용할 수 있다. 인식과 해석 네트워크는 서로 다른 층과 층의 숨겨진 RNN을 사용할 수 있다. 여기서는 인식과 해석 네트워크가 항상 동일한 수의 층과 숨겨진 크기의 RNN 셀을 사용한다고 가정하였다. 여기서 RNN 셀은 GRU 으로 형성되었다. GRU-L-H에서 GRU는 RNN 셀의 유형, L은 층수, H는 셀의 크기를 나타낸다. \n",
        "\n",
        "###실험 방법\n",
        "초기 학습율은 모든 훈련 모델에 대해 0.5로 두고 600번의 훈련과정을 거쳐 시험손실이 줄어들지 않으면 학습율은 0.99배 감소한다. 학습 속도가 1e - 7보다 작으면 훈련은 자동으로 중지된다.\n",
        "\n",
        "실험 결과는 정확히 일치하는 정도(EMA)와 추론 작업에 대한 분류 정확도(SSLA)로 나타낸다.\n",
        "\n",
        "Parameter \n",
        "\n",
        ">Multi-task balance weight λ, RNN층의 숨겨진 층의 크기와 층수\n",
        "\n",
        "![대체 텍스트](https://d3i71xaburhd42.cloudfront.net/0b940de618127f3d149fa3ca8e8bbba4b1cc425d/7-Table3-1.png)\n",
        "\n",
        "![대체 텍스트](https://d3i71xaburhd42.cloudfront.net/0b940de618127f3d149fa3ca8e8bbba4b1cc425d/7-Table4-1.png)\n",
        "\n",
        "![대체 텍스트](https://d3i71xaburhd42.cloudfront.net/0b940de618127f3d149fa3ca8e8bbba4b1cc425d/8-Figure4-1.png)\n",
        "\n",
        "![대체 텍스트](https://d3i71xaburhd42.cloudfront.net/0b940de618127f3d149fa3ca8e8bbba4b1cc425d/9-Figure5-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awl2qi8mRKh-",
        "colab_type": "text"
      },
      "source": [
        "Seq3seq가 정확도가 제일 높다. λ가 작아질수록 EMA는 높아지고 SSLA는 낮아진다. LD(숨겨진 크기)가 크면 정확도는 높아진다. 층수가 커질수록 오히려 정확도가 떨어지는 것으로 나타나는데 이는 데이터를 처리하는데 필요한 시간이 늘어나서 주어진 시간안에서는 성능이 떨어진 것으로 나타난다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j53g2gCRR3g",
        "colab_type": "text"
      },
      "source": [
        "##4.  CONCLUSIONS<br>\n",
        "새로운 방식의 반지도학습을 기반으로한 분자 예측 시스템인 seq3seq Fingerprint는 seq2seq와 다른 방식에 비해서 정확도가 높다. 이는 unlabeled data가 인식기 네트워크의 추론 성능을 크게 향상시키는 것으로 입증이된다. Seq3seq fingerprint 이론은 자연측정언어(NPL)과 공통적인 측면을 가지고 있기 때문에 NPL의 발전에 따라 seq3seq의 능력도 더 향상될 것으로 예상된다."
      ]
    }
  ]
}